{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment3 : Working with Spark SQL\n",
    "\n",
    "### Concepts :\n",
    "\n",
    "* Creating DataFrames from CSV input data format\n",
    "* Performing basic data analysis using Spark SQL\n",
    "* Saving a DataFrame into partitioned parquet files format\n",
    "* Using UDF function in PySpark\n",
    "\n",
    "### Assignment Dataset :\n",
    "\n",
    "* **Dataset** : format **parquet**\n",
    "* Available in the IE cluster @: /data/home/$YOU/spark_sessions/assignment3/data/parquet/\n",
    "* Dataset details : each entry in the dataset contains user name , id ,  salary , title , gender , country , etc\n",
    "\n",
    "\n",
    "### Compulsory Part  ( maximum possible points 10 ):\n",
    "\n",
    "1. Create a DataFrame using SparkSession and loading the input parquet dataset.\n",
    "2. Report the name of the columns and the nb of rows in the dataset. \n",
    "3. Create a in-memory DataFrame and a permantely stored table from this DataFrame.\n",
    "4. Report how many countries appear in the dataset. \n",
    "5. Report the top 10 countries with most users in the dataset. Use of the DataFrame API and a direct SQL query for this.\n",
    "6. Report the avg salary per country in the dataset. Use of the DataFrame API and a direct SQL query for this.\n",
    "7. Report the latest 10 registered users (name and surname) in the dataset , hint use the registration_dttm column\n",
    "8. Report the top 10 salaries from women in United States\n",
    "9. Cache the dataframe in memory   \n",
    "10.Save a subset dataFrame that only contains : id, birth date,  gender , country , salary , title , birthdate , comments \n",
    "    partitioning the country and gender into parquet format.\n",
    "    \n",
    "### Bonus Part ( maximum possible points 2 ):\n",
    "\n",
    "1. Using a UDF , transform the birthdate column into  timestamp \n",
    "2. Then report the number of French men in the dataset that were born before 1st January 1980\n",
    "\n",
    "### Note : \n",
    "\n",
    "* Usage of User Defined Functions is **only** strictly required for the bonus part\n",
    "\n",
    "### Help :\n",
    "\n",
    "* https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
