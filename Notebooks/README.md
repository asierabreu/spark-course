# Jupyter Notebooks 

Jupyter Notebooks will be used as the default 'environment' for the hands-on sessions. Note we may occassionally use Apache Zeppelin as a demonstrator of it's capabilities.


## References

The Jupyter official docs : http://jupyter-notebook.readthedocs.io/en/stable/notebook.html
Some Jupyter Notebooks : https://try.jupyter.org/
Spark API reference : https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD

## Setup steps

You have downloaded this repository to your local computer and are now connected to the Virtual Machine.

A reminder of the necessary setup stesp:

1. Download this repository to your local computer : git clone https://github.com/asierabreu/spark-course
2. cd spark-course
3. vagrant up ( and wait )
4. vagrant ssh

## Starting up a Notebook

A convenience script is provided : <i>start_notebook.sh<i> that will launch a PySpark shell and use the Jupyter Notebook as the driver program. On a terminal within the virtual machine (not your local computer) type:

* start_notebook.sh 

This will start-up a Jupyter notebook as the driver program of your spark application. The notebook is started up showing the contents of the Labs directory , just select the corresponding directory and notebook.

## Labs description

|Nb.|Id|Description|Status|
|1. |Lab1 | Introduction to Apache Spark  | Released |
|2. |Lab2 | | - |
|3. |Lab3 | | - |
|4. |Lab4 | | - |
|5. |Lab5 | | - |
|6. |Lab6 | | - |
|7. |Lab7 | | - |
|8. |Lab8 | | - |
|9. |Lab9 | | - |
|10.|Lab10| | - |
|11.|Lab11| | - |
|12.|Lab12| | - |