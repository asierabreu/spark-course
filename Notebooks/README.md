
# Hands-on Labs

These labs will be executed using the virtual cluster created. The cluster machines runs a Linux Ubuntu 16.0.4 OS and have pre-installed the following software packages:

1. Java Open JDK 1.8
2. Apache Spark 2.2.0 (including Hadoop 2.6)
3. Anaconda Python 3.6
4. Apache Zepellin 0.7.3 (TBD)

Jupyter Notebooks will be used as the default tool for the hands-on sessions. We may occassionally use Apache Zeppelin as a demonstrator of it's capabilities.

## References

1. The Jupyter official docs : http://jupyter-notebook.readthedocs.io/en/stable/notebook.html
2. Some Jupyter Notebooks : https://try.jupyter.org/
3. Spark API reference : https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD

## Setup steps

A reminder of the necessary setup steps for running the course notebooks

```
1. cd spark-course
2. vagrant ssh driver
3. source /spark-course/scripts/bash_setup.sh
4. start_notebook.sh
```

The later start-up a Jupyter notebook as the driver program of your spark application. The notebook is started up showing the contents of the Labs directory , just select the corresponding directory and notebook.

## Labs description

|Id|Description|Status|
|--|-----------|------|
|Lab0 | Introduction to Apache Spark  | **Released!** |
|Lab1 | | Not Available |
|Lab2 | | Not Available |
|Lab3 | | Not Available | 
|Lab4 | | Not Available |
|Lab5 | | Not Available | 
|Lab6 | | Not Available | 
|Lab7 | | Not Available | 
|Lab8 | | Not Available | 
|Lab9 | | Not Available |
|Lab10| | Not Available | 
|Lab11| | Not Available | 
|Lab12| | Not Available | 
